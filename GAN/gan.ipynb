{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bac6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d92db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GANを書いてみる\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows,self.img_cols,self.channels)\n",
    "        # 潜在変数の次元数\n",
    "        self.z_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002,0.5)\n",
    "        # 識別器モデル\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer = optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "    \n",
    "        # 生成器モデル\n",
    "        self.generator = self.build_generator()\n",
    "        # generatorは単体で学習しないのでコンパイルは必要ない\n",
    "\n",
    "        self.combined = self.build_combined1()\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256,input_shape = noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summaty()\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = (self.img_rows,self.img_cols,self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def build_combined1(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator,self.discriminator])\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
